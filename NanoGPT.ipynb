{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d68765b-e8f8-4547-8e6f-b5b9f84014f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42da93b-940a-4cbf-9f0e-95d8f8684b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-19 01:01:08--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-12-19 01:01:09 (13.5 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae1c0f06-2342-455f-8e99-abf684ddca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "045ed76b-647e-4022-93ef-a566a435adf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66f6a83b-38b6-4c2a-a509-780b7a5f16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ead11ffb-d05b-495d-8430-32f124e32fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're doing character level token encoding - no semantic meaning is captured in this\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5177ad92-6057-4aec-862f-934dadbaa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(str):\n",
    "    return [stoi[s] for s in str]\n",
    "def decode(vec):\n",
    "    return ''.join([itos[i] for i in vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3d5e94b-ee74-41ca-a90f-fc2832501007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Byte Pair Encoding\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "tokens = enc.encode(text)\n",
    "data = torch.tensor(tokens, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4cf42eb-9ab0-4425-a17c-d11458d26aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = enc.n_vocab\n",
    "\n",
    "def decode_BPE(tokens):\n",
    "    return enc.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "614e5f12-d40a-4d2a-8032-01d1d82a4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Char level\n",
    "#sample = \"Yo, what's up?\"\n",
    "#print(encode(sample))\n",
    "#print(decode(encode(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "186fe9c0-3150-470f-99ef-100765bddbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38101, 11, 644, 338, 510, 30]\n",
      "Yo, what's up?\n"
     ]
    }
   ],
   "source": [
    "#BPE\n",
    "sample = \"Yo, what's up?\"\n",
    "print(enc.encode(sample))\n",
    "print(decode_BPE(enc.encode(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "614019a2-75be-4b76-a697-62feb79b8e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f5708808-2af5-4785-ac99-76e81a92c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int32\n"
     ]
    }
   ],
   "source": [
    "#data = torch.tensor(encode(text), dtype=torch.int)\n",
    "#print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bcbc3cd-9b8e-48fd-b7fb-e678d8d2d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36cc11bb-54a1-48ee-9222-c380abe8b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb: tensor([[ 6711,    25,   198,  ...,   423,  2074,  1549],\n",
      "        [  284, 13197,   465,  ...,   683,    26,   198],\n",
      "        [   11,  2074,    26,  ..., 44879,    40,  3535],\n",
      "        ...,\n",
      "        [  198,  5122,  2988,  ...,   198,  2348,   292],\n",
      "        [  475,   484,   547,  ..., 11083,   286,  1971],\n",
      "        [ 3223,  9538,  1657,  ...,   338,  9482,    11]], device='mps:0')\n",
      "yb: tensor([[   25,   198,    35,  ...,  2074,  1549,   287],\n",
      "        [13197,   465, 10645,  ...,    26,   198,     6],\n",
      "        [ 2074,    26,   892,  ...,    40,  3535,  1565],\n",
      "        ...,\n",
      "        [ 5122,  2988,  1203,  ...,  2348,   292,    11],\n",
      "        [  484,   547,  4844,  ...,   286,  1971,   198],\n",
      "        [ 9538,  1657,    25,  ...,  9482,    11,   198]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "B = 8 #batch size\n",
    "T = 256 #sequence length\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def get_batch(split, T):\n",
    "    sample = train if split == 'train' else val\n",
    "    idx = torch.randint(len(sample) - T, (B,))\n",
    "    x = torch.stack([sample[i:i+T] for i in idx])\n",
    "    y = torch.stack([sample[i+1:i+T+1] for i in idx])\n",
    "    return x.to(device), y.to(device)\n",
    "    \n",
    "xb, yb = get_batch('train', T)\n",
    "print(\"xb:\", xb)\n",
    "print(\"yb:\", yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17a129eb-1510-4dfe-860a-1ce07c272e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CausalSelfAttentionHead(nn.Module):\n",
    "    def __init__(self, n_embd, head_size, block_size):\n",
    "        super().__init__()\n",
    "        self.k = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.q = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.v = nn.Linear(n_embd, head_size, bias = False)\n",
    "\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        k = self.k(x) # (B, T, head_size)\n",
    "        q = self.q(x) # (B, T, head_size)\n",
    "        v = self.v(x) # (B, T, head_size)\n",
    "\n",
    "        #scaled dot product of key and query\n",
    "        attn = (q @ k.transpose(-2, -1)) / (k.size(-1)**0.5)\n",
    "\n",
    "        #casual mask\n",
    "        attn = attn.masked_fill(self.tril[:T, :T]==0, float(\"-inf\")) #tril creates a triangular lower half matrix, masked fill replaces futures tokens i.e. ones with 0 (due to tril) with - inf: which becomes 0 after softmax\n",
    "                              \n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "\n",
    "        return attn @ v # (B, T, head_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "700ee43c-e263-4e10-9d88-673e0a304c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, n_embd, block_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        head_size = n_embd // n_head\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            CausalSelfAttentionHead(n_embd, head_size, block_size)\n",
    "            for _ in range(n_head)\n",
    "        ])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim =-1)\n",
    "        return self.proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e32b9934-acd5-40dd-b42a-92aa0024860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4*n_embd),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(n_embd*4, n_embd)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48ae6fa8-a0e4-41c3-ac06-5c24077b4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, block_size):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.attn = MultiHeadAttention(n_head, n_embd, block_size)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        self.mlp = MLP(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "709f0064-a9e7-4bb9-9dc9-3fe18e4d6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self,vocab_size, n_embd, n_head, n_layer, block_size):\n",
    "        super().__init__()\n",
    "\n",
    "        #embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_emb = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        #transformer block\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[TransformerBlock(n_embd, n_head, block_size) for _ in range(n_layer)]\n",
    "        )\n",
    "        \n",
    "        #Final Layer Norm\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size, bias = False)\n",
    "\n",
    "        # weight tying (GPT-2 style)\n",
    "        self.lm_head.weight = self.token_emb.weight\n",
    "\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        \"\"\"\n",
    "        idx : (B, T)\n",
    "        targets: (B, T) or none\n",
    "        \"\"\"\n",
    "        B, T = idx.shape\n",
    "        assert T <= self.block_size, \"Sequence length exceeds block size\"\n",
    "\n",
    "        # embeddings\n",
    "        tok = self.token_emb(idx)  # (B, T, n_embd)\n",
    "        pos = self.pos_emb(torch.arange(T, device=idx.device))  # (T, n_embd)\n",
    "        x = tok + pos  # (B, T, n_embd)\n",
    "\n",
    "        # transformer\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        # logits\n",
    "        logits = self.lm_head(x)  # (B, T, vocab_size)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            logits = logits.view(-1, self.vocab_size)\n",
    "            targets = targets.view(-1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "463d78f5-a2a9-44aa-8a2c-3071af5ad774",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, idx, max_new_tokens):\n",
    "    device = next(model.parameters()).device\n",
    "    idx = idx.to(device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -model.block_size:]\n",
    "\n",
    "        logits, _ = model(idx_cond)\n",
    "        logits = logits[:, -1, :]          # (B, vocab)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # MPS-safe sampling\n",
    "        idx_next = torch.multinomial(\n",
    "            probs.cpu(), num_samples=1\n",
    "        ).to(device)\n",
    "\n",
    "        idx = torch.cat([idx, idx_next], dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a05c277f-5b0f-4f26-a520-9c6ab07ea99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_size = 50257 # already defined earlier\n",
    "n_embd = 256 #embedding dimension\n",
    "n_head = 8\n",
    "n_layer = 6\n",
    "block_size = 256 #max context length\n",
    "\n",
    "model = GPT(\n",
    "    vocab_size = vocab_size,\n",
    "    n_embd = n_embd,\n",
    "    n_head = n_head,\n",
    "    n_layer = n_layer,\n",
    "    block_size = block_size\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a6d6ffc-497b-449f-8999-e83b5d17190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3d600d7-4d78-47aa-898b-ccc28668e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 | loss 4.5180\n",
      "step 100 | loss 4.4793\n",
      "step 200 | loss 4.2571\n",
      "step 300 | loss 3.9151\n",
      "step 400 | loss 4.5281\n",
      "step 500 | loss 4.2226\n",
      "step 600 | loss 3.8728\n",
      "step 700 | loss 4.0065\n",
      "step 800 | loss 4.4602\n",
      "step 900 | loss 4.1559\n",
      "step 1000 | loss 4.0248\n",
      "step 1100 | loss 4.3312\n",
      "step 1200 | loss 4.2090\n",
      "step 1300 | loss 3.7860\n",
      "step 1400 | loss 4.0280\n",
      "step 1500 | loss 4.0067\n",
      "step 1600 | loss 4.1319\n",
      "step 1700 | loss 3.7496\n",
      "step 1800 | loss 3.6849\n",
      "step 1900 | loss 4.0623\n",
      "step 2000 | loss 4.2197\n",
      "step 2100 | loss 3.5693\n",
      "step 2200 | loss 3.9186\n",
      "step 2300 | loss 3.9745\n",
      "step 2400 | loss 3.6727\n",
      "step 2500 | loss 3.2856\n",
      "step 2600 | loss 3.2693\n",
      "step 2700 | loss 3.8220\n",
      "step 2800 | loss 3.4356\n",
      "step 2900 | loss 3.7082\n",
      "step 3000 | loss 3.3516\n",
      "step 3100 | loss 3.1928\n",
      "step 3200 | loss 3.6121\n",
      "step 3300 | loss 3.5367\n",
      "step 3400 | loss 3.0117\n",
      "step 3500 | loss 3.4192\n",
      "step 3600 | loss 2.9645\n",
      "step 3700 | loss 3.1129\n",
      "step 3800 | loss 3.1557\n",
      "step 3900 | loss 3.1249\n",
      "step 4000 | loss 3.1448\n",
      "step 4100 | loss 3.2409\n",
      "step 4200 | loss 3.1211\n",
      "step 4300 | loss 3.1679\n",
      "step 4400 | loss 3.1023\n",
      "step 4500 | loss 3.1001\n",
      "step 4600 | loss 2.7937\n",
      "step 4700 | loss 2.4399\n",
      "step 4800 | loss 2.3823\n",
      "step 4900 | loss 3.1131\n",
      "step 5000 | loss 2.9547\n",
      "step 5100 | loss 2.4231\n",
      "step 5200 | loss 2.7146\n",
      "step 5300 | loss 2.6053\n",
      "step 5400 | loss 2.5645\n",
      "step 5500 | loss 2.4091\n",
      "step 5600 | loss 2.6344\n",
      "step 5700 | loss 2.3968\n",
      "step 5800 | loss 2.3837\n",
      "step 5900 | loss 2.2992\n",
      "step 6000 | loss 2.3331\n",
      "step 6100 | loss 2.3413\n",
      "step 6200 | loss 2.2122\n",
      "step 6300 | loss 1.9353\n",
      "step 6400 | loss 2.4994\n",
      "step 6500 | loss 2.1507\n",
      "step 6600 | loss 1.9945\n",
      "step 6700 | loss 1.9031\n",
      "step 6800 | loss 1.9467\n",
      "step 6900 | loss 1.9774\n",
      "step 7000 | loss 1.8416\n",
      "step 7100 | loss 1.8385\n",
      "step 7200 | loss 1.7241\n",
      "step 7300 | loss 1.5797\n",
      "step 7400 | loss 1.5642\n",
      "step 7500 | loss 1.5433\n",
      "step 7600 | loss 1.4956\n",
      "step 7700 | loss 1.3511\n",
      "step 7800 | loss 1.5098\n",
      "step 7900 | loss 1.6031\n",
      "step 8000 | loss 1.2828\n",
      "step 8100 | loss 1.5091\n",
      "step 8200 | loss 1.4040\n",
      "step 8300 | loss 1.3502\n",
      "step 8400 | loss 1.1307\n",
      "step 8500 | loss 1.2376\n",
      "step 8600 | loss 1.1868\n",
      "step 8700 | loss 1.1144\n",
      "step 8800 | loss 1.3295\n",
      "step 8900 | loss 1.2781\n",
      "step 9000 | loss 0.8798\n",
      "step 9100 | loss 1.2041\n",
      "step 9200 | loss 0.9990\n",
      "step 9300 | loss 1.0339\n",
      "step 9400 | loss 1.0336\n",
      "step 9500 | loss 0.8897\n",
      "step 9600 | loss 0.8232\n",
      "step 9700 | loss 0.8566\n",
      "step 9800 | loss 0.8478\n",
      "step 9900 | loss 0.6476\n",
      "step 10000 | loss 0.7476\n",
      "step 10100 | loss 0.7560\n",
      "step 10200 | loss 0.6668\n",
      "step 10300 | loss 0.6544\n",
      "step 10400 | loss 0.6249\n",
      "step 10500 | loss 0.7545\n",
      "step 10600 | loss 0.6780\n",
      "step 10700 | loss 0.7797\n",
      "step 10800 | loss 0.6323\n",
      "step 10900 | loss 0.7750\n",
      "step 11000 | loss 0.6248\n",
      "step 11100 | loss 0.7212\n",
      "step 11200 | loss 0.6493\n",
      "step 11300 | loss 0.7141\n",
      "step 11400 | loss 0.6427\n",
      "step 11500 | loss 0.6936\n",
      "step 11600 | loss 0.6240\n",
      "step 11700 | loss 0.6307\n",
      "step 11800 | loss 0.4540\n",
      "step 11900 | loss 0.5617\n",
      "CPU times: user 20min 25s, sys: 51min 12s, total: 1h 11min 37s\n",
      "Wall time: 1h 57min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_steps = 12000\n",
    "\n",
    "for step in range(num_steps):\n",
    "    xb, yb = get_batch(\"train\", T)  # (B, T), (B, T)\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"step {step} | loss {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92ca61d4-b287-4502-a79f-c38279269a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be, or not to be gall\n",
      "Against a tongue rasciv to come; at the hands\n",
      "The child if deny to take him.\n",
      "\n",
      " ble lineal, ho! what dissolution!\n",
      "'Yourbroke, or at bone!\n",
      "Who is that thy lodging:\n",
      "This exile is great pound come?\n",
      "The sounded by my heart; who, every one hap is sweet;\n",
      "Banish'd is dark to went with high?\n",
      "The treachery heaven wilderness is wash'd,\n",
      "And who part in high ready sense; unless\n",
      "The contrary doth death,\n",
      "The contrary and do a want of false one that is servant,\n",
      "To this breathingr'd, as a secrets in second hopes,\n",
      "For hers, all a purpose.\n",
      "Whereto, fools, devise dear Romeo by thee;\n",
      "She shall not thy lance.\n",
      "He shall not name his father that No: let me speak,\n",
      "It shall not be reign as it be to no.\n",
      "Strike up with\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor(\n",
    "    enc.encode(\"To be, or not to be\"),\n",
    "    dtype=torch.long,\n",
    "    device=device\n",
    ").unsqueeze(0)\n",
    "\n",
    "out = generate(model, context, max_new_tokens=200)\n",
    "print(enc.decode(out[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87a3e685-7267-4dfe-b20e-786aa98bf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"gpt_bpe_shakespeare.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c22bf68-4fee-43f4-b48c-d0fe329b33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"config\": {\n",
    "        \"vocab_size\": vocab_size,\n",
    "        \"n_embd\": n_embd,\n",
    "        \"n_head\": n_head,\n",
    "        \"n_layer\": n_layer,\n",
    "        \"block_size\": block_size,\n",
    "    },\n",
    "    \"step\": step,\n",
    "    \"loss\": loss.item(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \"gpt_checkpoint.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "741ab61e-391a-4e5b-bcef-9230da3664b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "    \"step\": step,\n",
    "}\n",
    "torch.save(checkpoint, \"gpt_resume.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebac56-7579-4efe-adc8-1d2d8f122d7a",
   "metadata": {},
   "source": [
    "# Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdfec5aa-01fd-4b53-bfb4-0e75f8b5849b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_emb): Embedding(50257, 256)\n",
       "  (pos_emb): Embedding(256, 256)\n",
       "  (blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x CausalSelfAttentionHead(\n",
       "            (k): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (q): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x CausalSelfAttentionHead(\n",
       "            (k): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (q): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x CausalSelfAttentionHead(\n",
       "            (k): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (q): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x CausalSelfAttentionHead(\n",
       "            (k): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (q): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x CausalSelfAttentionHead(\n",
       "            (k): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (q): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x CausalSelfAttentionHead(\n",
       "            (k): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (q): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=256, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"gpt_checkpoint.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model = model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "834eb8c8-f16c-49d7-8f69-c1c0fbad4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To resume training\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93feae50-6d78-4c7a-a300-5310befc9ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
